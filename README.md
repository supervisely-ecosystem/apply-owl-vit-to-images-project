<div align="center" markdown>

<img src="docs/images/poster.png">

# Owl-ViT-app
Integration of the Owl-ViT model for class-agnostic object detection

<p align="center">
  <a href="#Overview">Overview</a> •
  <a href="#How-to-Use">How to use</a> •
  <a href="#Demo">Demo</a>
</p>

[![](https://img.shields.io/badge/supervisely-ecosystem-brightgreen)](https://ecosystem.supervise.ly/apps/supervisely-ecosystem/apply-owl-vit-to-images-project)
[![](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://supervise.ly/slack)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/supervisely-ecosystem/apply-owl-vit-to-images-project)
[![views](https://app.supervise.ly/img/badges/views/supervisely-ecosystem/apply-owl-vit-to-images-project.png)](https://supervise.ly)
[![runs](https://app.supervise.ly/img/badges/runs/supervisely-ecosystem/apply-owl-vit-to-images-project.png)](https://supervise.ly)

</div>

# Overview
Application allows you to label projects images using Owl-ViT detection model.

Application key points:

- Select project to label
- Choose the model configuration for local run or run via [serve owl-vit app](https://github.com/supervisely-ecosystem/serve-owl-vit) 
- Set up model input data as text-prompt or reference-image
- Preview detection results
- Apply model to project images and save new annotations to new project or add to existed  

# Results screenshoot
<details>
<summary>Reference-image</summary>
<img src="docs/images/screenshoot.png" />
</details>

<details>
<summary>Text-prompt</summary>
<img src="docs/images/screenshoot.png" />
</details>